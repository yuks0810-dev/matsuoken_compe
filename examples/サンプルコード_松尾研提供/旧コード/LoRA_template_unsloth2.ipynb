{"cells":[{"cell_type":"markdown","metadata":{"id":"Y7Wdw0O6o2xa"},"source":["## 最終課題コンペ用 Fine-tuning テンプレート（unsloth）\n","\n","最終課題コンペにて Fine-tuning を行ないたい方に向けの Fine-tuning コードです。  \n","Unsloth を使うことで Google Colab の無料で利用可能な T4 でも動作可能になっています。\n","環境設定の難易度が高いので、慎重に取り組んでいただければと思います。\n","\n","\n","### terminalでのconda環境構築\n","事前にterminalで環境構築の必要があります。Google Colabでは不要です。  \n","```\n","# conda環境の構築\n","wget \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"  \n","\n","# このコマンドではいくつか質問があるので答えて下さい。おそらくインストール先のデフォルトは/root/miniforge3かと思います  \n","bash Miniforge3-$(uname)-$(uname -m).sh  \n","\n","# 以下、インストール先が/root/miniforge3であることを前提とします  \n","export PATH=/root/miniforge3/bin:$PATH  \n","conda init  \n","\n","# ここで一度、terminalを立ち上げ直す必要があります。  \n","# 以下のリンク先に従い環境を作ります。  \n","# https://docs.unsloth.ai/get-started/installation/conda-install  \n","conda create --name unsloth_env python=3.10 pytorch-cuda=12.1 pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers -y  \n","conda activate unsloth_env  \n","pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"  \n","pip install --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes  \n","\n","# jupyter notebook用のセットアップ。  \n","conda install -c conda-forge ipykernel  \n","python -m ipykernel install --user --name=unsloth_env --display-name \"Python (unsloth_env)\"  \n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeKrhsB3Q_3H","executionInfo":{"status":"ok","timestamp":1732336873516,"user_tz":-540,"elapsed":33855,"user":{"displayName":"Yuta Hayashi","userId":"16353596730523707040"}},"outputId":"545121bf-1407-4644-d8d3-bb48b1248804"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping unsloth as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-raz8p9i3/unsloth_77cd993d12104bb7a4f86af9c4d87545\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-raz8p9i3/unsloth_77cd993d12104bb7a4f86af9c4d87545\n","  Resolved https://github.com/unslothai/unsloth.git to commit 228b3cf46ec4401b81194267ed0091eb62a56c6b\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting unsloth_zoo>=2024.11.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading unsloth_zoo-2024.11.7-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n","Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading tyro-0.9.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.46.2)\n","Collecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n","Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.26.2)\n","Collecting hf_transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n","Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.3)\n","Collecting triton (from unsloth_zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.1.1)\n","Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth_zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading trl-0.12.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading cut_cross_entropy-24.11.4-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.0.0)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n","Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n","Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m229.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m341.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m304.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2024.11.7-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m247.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.1-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.9/111.9 kB\u001b[0m \u001b[31m344.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m335.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m321.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m332.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading trl-0.12.1-py3-none-any.whl (310 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m321.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-24.11.4-py3-none-any.whl (22 kB)\n","Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m270.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m320.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2024.11.9-py3-none-any.whl size=166001 sha256=491ae73edda58e5983dd08f197d9d48acced4dd36164a855f964df2dde36566f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-d5eh0ka6/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n","Successfully built unsloth\n","Installing collected packages: xxhash, unsloth, triton, shtab, protobuf, hf_transfer, fsspec, dill, multiprocess, tyro, cut_cross_entropy, bitsandbytes, datasets, trl, unsloth_zoo\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n","grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.44.1 cut_cross_entropy-24.11.4 datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 hf_transfer-0.1.8 multiprocess-0.70.16 protobuf-3.20.3 shtab-1.7.1 triton-3.1.0 trl-0.12.1 tyro-0.9.1 unsloth-2024.11.9 unsloth_zoo-2024.11.7 xxhash-3.5.0\n"]}],"source":["# Google Colab の場合は上記の環境構築手順を行なわず、単にこのセルから実行していってください。\n","!pip uninstall unsloth -y\n","!pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""]},{"cell_type":"code","source":["# Google Colab のデフォルトで入っているパッケージをアップグレード（Moriyasu さんありがとうございます）\n","!pip install --upgrade torch\n","!pip install --upgrade xformers"],"metadata":{"id":"knPVRpxkXSNW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-t3HhxN8joX"},"outputs":[],"source":["# notebookでインタラクティブな表示を可能とする（ただし、うまく動かない場合あり）\n","!pip install ipywidgets --upgrade\n","\n","# Install Flash Attention 2 for softcapping support\n","import torch\n","if torch.cuda.get_device_capability()[0] >= 8:\n","    !pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbmtYWUH8p_J","colab":{"base_uri":"https://localhost:8080/","height":378},"executionInfo":{"status":"error","timestamp":1732336830753,"user_tz":-540,"elapsed":5724,"user":{"displayName":"Yuta Hayashi","userId":"16353596730523707040"}},"outputId":"96bf77f2-7185-4c29-a175-0cf107e0f042"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'unsloth'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3fbd2efa0c29>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m \u001b[0;31m# unslothではRoPEをサポートしているのでコンテキスト長は自由に設定可能\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unsloth'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# llm-jp/llm-jp-3-13bを4bit量子化のqLoRA設定でロード。\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 512 # unslothではRoPEをサポートしているのでコンテキスト長は自由に設定可能\n","dtype = None # Noneにしておけば自動で設定\n","load_in_4bit = True # 今回は8Bクラスのモデルを扱うためTrue\n","\n","model_id = \"llm-jp/llm-jp-3-13b\"\n","new_model_id = \"llm-jp-3-13b-it\" #Fine-Tuningしたモデルにつけたい名前、it: Instruction Tuning\n","# FastLanguageModel インスタンスを作成\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=model_id,\n","    dtype=dtype,\n","    load_in_4bit=load_in_4bit,\n","    trust_remote_code=True,\n",")\n","\n","# SFT用のモデルを用意\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 32,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 32,\n","    lora_dropout = 0.05,\n","    bias = \"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 3407,\n","    use_rslora = False,\n","    loftq_config = None,\n","    max_seq_length = max_seq_length,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAaS0RKXgG72"},"outputs":[],"source":["# Hugging Face Token を指定\n","# 下記の URL から Hugging Face Token を取得できますので下記の HF_TOKEN に入れてください。\n","# https://huggingface.co/settings/tokens\n","HF_TOKEN = \"\" #@param {type:\"string\"}\n","\n","# あるいは Google Colab シークレットを使う場合、左のサイドバーより🔑マークをクリック\n","# HF_TOKEN という名前で Value に Hugging Face Token を入れてください。\n","# ノートブックからのアクセスのトグルをオンにし、下記の二行のコードのコメントアウトを外してください。\n","\n","# from google.colab import userdata\n","# HF_TOKEN=userdata.get('HF_TOKEN')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RT0wnFkYjNpO"},"outputs":[],"source":["# 学習に用いるデータセットの指定\n","# 今回はLLM-jp の公開している Ichikara Instruction を使います。データにアクセスするためには申請が必要ですので、使いたい方のみ申請をしてください。\n","# Ichikara Instruciton を Hugging Face Hub にて公開することはお控えください。\n","\n","# 下記のリンクから申請を終えた先に Google Drive があり、Distribution20241221_all というフォルダごとダウンロードしてください。\n","# 今回は「ichikara-instruction-003-001-1.json」を使います。必要であれば展開（!unzip など）し、データセットのパスを適切に指定してください。\n","# omnicampusの開発環境では取得したデータを左側にドラッグアンドドロップしてお使いください。\n","# Google Colab の場合も左のサイドバーよりドラッグ&ドロップでアップデートしてください。\n","\n","# https://liat-aip.sakura.ne.jp/wp/llmのための日本語インストラクションデータ作成/llmのための日本語インストラクションデータ-公開/\n","# 関根聡, 安藤まや, 後藤美知子, 鈴木久美, 河原大輔, 井之上直也, 乾健太郎. ichikara-instruction: LLMのための日本語インストラクションデータの構築. 言語処理学会第30回年次大会(2024)\n","\n","from datasets import load_dataset\n","\n","dataset = load_dataset(\"json\", data_files=\"/content/ichikara-instruction-003-001-1.json\")\n","# パスの指定にご注意ください。アップロードしたファイルを右クリックし、「パスをコピー」をクリック、上記の data_files と合致していることをご確認ください。Omnicampus のディレクトリ構造とは異なるかもしれません。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BANlYJFSKf-K"},"outputs":[],"source":["# 学習時のプロンプトフォーマットの定義\n","prompt = \"\"\"### 指示\n","{}\n","### 回答\n","{}\"\"\"\n","\n","\n","\n","\"\"\"\n","formatting_prompts_func: 各データをプロンプトに合わせた形式に合わせる\n","\"\"\"\n","EOS_TOKEN = tokenizer.eos_token # トークナイザーのEOSトークン（文末トークン）\n","def formatting_prompts_func(examples):\n","    input = examples[\"text\"] # 入力データ\n","    output = examples[\"output\"] # 出力データ\n","    text = prompt.format(input, output) + EOS_TOKEN # プロンプトの作成\n","    return { \"formatted_text\" : text, } # 新しいフィールド \"formatted_text\" を返す\n","pass\n","\n","# # 各データにフォーマットを適用\n","dataset = dataset.map(\n","    formatting_prompts_func,\n","    num_proc= 4, # 並列処理数を指定\n",")\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8NhF0GLaTkUZ"},"outputs":[],"source":["# データを確認\n","print(dataset[\"train\"][\"formatted_text\"][3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHSyrGcEQ_3I"},"outputs":[],"source":["\"\"\"\n","training_arguments: 学習の設定\n","\n","  - output_dir:\n","      -トレーニング後のモデルを保存するディレクトリ\n","\n","  - per_device_train_batch_size:\n","      - デバイスごとのトレーニングバッチサイズ\n","\n","  - per_device_eval_batch_size:\n","      - デバイスごとの評価バッチサイズ\n","\n","  - gradient_accumulation_steps:\n","      - 勾配を更新する前にステップを積み重ねる回数\n","\n","  - optim:\n","      - オプティマイザの設定\n","\n","  - num_train_epochs:\n","      - エポック数\n","\n","  - eval_strategy:\n","      - 評価の戦略 (\"no\"/\"steps\"/\"epoch\")\n","\n","  - eval_steps:\n","      - eval_strategyが\"steps\"のとき、評価を行うstep間隔\n","\n","  - logging_strategy:\n","      - ログ記録の戦略\n","\n","  - logging_steps:\n","      - ログを出力するステップ間隔\n","\n","  - warmup_steps:\n","      - 学習率のウォームアップステップ数\n","\n","  - save_steps:\n","      - モデルを保存するステップ間隔\n","\n","  - save_total_limit:\n","      - 保存しておくcheckpointの数\n","\n","  - max_steps:\n","      - トレーニングの最大ステップ数\n","\n","  - learning_rate:\n","      - 学習率\n","\n","  - fp16:\n","      - 16bit浮動小数点の使用設定（第8回演習を参考にすると良いです）\n","\n","  - bf16:\n","      - BFloat16の使用設定\n","\n","  - group_by_length:\n","      -  入力シーケンスの長さによりバッチをグループ化 (トレーニングの効率化)\n","\n","  - report_to:\n","      - ログの送信先 (\"wandb\"/\"tensorboard\"など)\n","\"\"\"\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset=dataset[\"train\"],\n","    max_seq_length = max_seq_length,\n","    dataset_text_field=\"formatted_text\",\n","    packing = False,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        num_train_epochs = 1,\n","        logging_steps = 10,\n","        warmup_steps = 10,\n","        save_steps=100,\n","        save_total_limit=2,\n","        max_steps=-1,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        group_by_length=True,\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3U8FUkwTx_K"},"outputs":[],"source":["#@title 現在のメモリ使用量を表示\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjrchK4hSr0b"},"outputs":[],"source":["#@title 学習実行\n","trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_P7-b0_Q_3J"},"outputs":[],"source":["# ELYZA-tasks-100-TVの読み込み。事前にファイルをアップロードしてください\n","# データセットの読み込み。\n","# omnicampusの開発環境では、左にタスクのjsonlをドラッグアンドドロップしてから実行。\n","import json\n","datasets = []\n","with open(\"./elyza-tasks-100-TV_0.jsonl\", \"r\") as f:\n","    item = \"\"\n","    for line in f:\n","      line = line.strip()\n","      item += line\n","      if item.endswith(\"}\"):\n","        datasets.append(json.loads(item))\n","        item = \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsbwPAOJQ_3J"},"outputs":[],"source":["# 学習したモデルを用いてタスクを実行\n","from tqdm import tqdm\n","\n","# 推論するためにモデルのモードを変更\n","FastLanguageModel.for_inference(model)\n","\n","results = []\n","for dt in tqdm(datasets):\n","  input = dt[\"input\"]\n","\n","  prompt = f\"\"\"### 指示\\n{input}\\n### 回答\\n\"\"\"\n","\n","  inputs = tokenizer([prompt], return_tensors = \"pt\").to(model.device)\n","\n","  outputs = model.generate(**inputs, max_new_tokens = 512, use_cache = True, do_sample=False, repetition_penalty=1.2)\n","  prediction = tokenizer.decode(outputs[0], skip_special_tokens=True).split('\\n### 回答')[-1]\n","\n","  results.append({\"task_id\": dt[\"task_id\"], \"input\": input, \"output\": prediction})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pd8VbKeIQ_3J"},"outputs":[],"source":["# jsonlで保存\n","with open(f\"{new_model_id}_output.jsonl\", 'w', encoding='utf-8') as f:\n","    for result in results:\n","        json.dump(result, f, ensure_ascii=False)\n","        f.write('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zq4Ko1FWakX9"},"outputs":[],"source":["# モデルとトークナイザーをHugging Faceにアップロード。\n","# 一旦privateでアップロードしてください。\n","# 最終成果物が決まったらpublicにするようお願いします。\n","# 現在公開しているModel_Inference_Template.ipynbはunslothを想定していないためそのままでは動かない可能性があります。\n","model.push_to_hub_merged(\n","    new_model_id,\n","    tokenizer=tokenizer,\n","    save_method=\"lora\",\n","    token=HF_TOKEN,\n","    private=True\n",")\n","\n","# model.push_to_hub(new_model_id, token=HF_TOKEN, private=True) # Online saving\n","# tokenizer.push_to_hub(new_model_id, token=HF_TOKEN) # Online saving"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}